September 2020

Experiment 1:
  - Train on 5,069 dependency graphs, #(contexts) = 135,825, #(distinctFeatures) = 274,411, #(features with count >= 2) = 126,762
  - 149 transitions (including second-level labels)
  - MLR, f=2, u=32,768 => training accuracy: uas = 0.6745043798985708, las = 0.6359945699503099 (MBP)
  - MLR, f=2, u=65,536 => training accuracy: uas = 0.8756467394088417, las = 0.860547615388556 (jupiter)
  - MLR, f=2, u=100,000 => training accuracy: uas = 0.951065519184468, las = 0.9446493519799191 (jupiter)
  - MLR, f=2, u=120,000 => training accuracy: uas = 0.9740920034834281, las = 0.9701219199836074 (jupiter)

Experiment 2:
  - Training/test split: 80/20. Random seed = 220712. #(training) = 4,055, #(test) = 1,014
  - #(distinctFeatures) = 234241, #(features with count >= 2) = 106791
  - Use only first-level labels.
  - MLR, f=2, u=65,536  => test accuracy: uas = 0.5865950370938859, las = 0.4826682015860834 (MBP)
  - MLR, f=2, u=100,000 => test accuracy: uas = 0.6011767715528268, las = 0.5067152724481965 (jupiter)
  - MLP, f=2, u=16,384, h=128 => test accuracy: uas = 0.366525965720133, las = 0.2541570734203121 (jupiter)

Experiment 3: Train all 5K graphs for parser API.
  - MLR, f=2, u=120,000 => training accuracy: uas = 0.9833384560217202, las = 0.98058501101378 (jupiter) => `/opt/models/tdp/vie/mlr`
  - MLR, f=2, u=100,000 => training accuracy: uas = 0.9706982224271298, las = 0.9667025254853747 (MBP) => `dat/tdp/vie/mlr`

===
1. MLR for Vietnamese

  #(trainingGraphs) = 1400
  #(developmentGraphs) = 800

1.1. numFeatures = 1024

  dev., train.
  0.7861776097811377, 0.8757247623838395
  0.7877642447151056, 0.8689735511371158

1.2. numFeatures = 2048

  0.7727845443091138, 0.9091366392205661
  0.7692379485743619, 0.9054300918694236

1.3. numFeatures = 4096

  0.748331700032666, 0.9470493235551084 
  uas = 0.5082832548318986, las = 0.43998700665908724

1.4. numFeatures = 8192

  0.7321853562928742, 0.980461200391835
  uas = 0.5454766931947377, las = 0.4697092739970765

1.5. numFeatures = 16384

  0.7249055018899622, 0.9946255063408435
  uas = 0.5778788370959883, las = 0.5078772129283742

1.6. numFeatures = 32768

  0.7366652666946661, 0.9978290222657594
  uas = 0.5835634237453305, las = 0.5263927237290889

1.7. numFeatures = 65536

  0.7399785337626581, 0.999046887823992
    uas = 0.5912782199122949, las = 0.5302907260029235
    uas = 0.9952501729305971, las = 0.9950657136269311


2. MLP for Vietnamese

2.1. No hidden layer:

numFeatures = 8192
  0.7676979793737458, 0.9792698101718249
  uas = 0.34091278219912297, las = 0.3072113042065941
  uas = 0.3824302513258012, las = 0.36725847359926217

numFeatures = 16384
  0.7737645247095059, 0.9948637843848455
  uas = 0.3657625466948189, las = 0.3326295273672243
  uas = 0.4142033663822919, las = 0.40308969333640765

numFeatures = 32768

  0.7917308320500257,  0.9978554976039818
    0.34740945265551404, las = 0.3224784797791132
    
  0.7887442251154977, 0.9981202509862064
    uas = 0.3505765795030047, las = 0.3249147312002599
    uas = 0.41268157712704634, las = 0.4048881715471524

numFeatures = 65536
    0.7907975173829856, 0.9990733631622144
    0.7918241635167297, 0.999046887823992
    uas = 0.32369660548968654, las = 0.3012018840344324
    uas = 0.3821074475443855, las = 0.374959649527323

2.2. One hidden layer of 64 units

numFeatures = 8192
  0.7805777217788977,  0.9915278917688174
  uas = 0.46654214714958586, las = 0.40596069514373884
  uas = 0.5056951810006918, las = 0.4594881254323265

numFeatures = 16384
  0.7872042559148817, 0.9964258293399698
  uas = 0.5042228357966542, las = 0.43381516972551565
  uas = 0.5850587964030436, las = 0.534148028591192


2.3. One hidden layer of 128 units

numFeatures = 2048
  0.7775444491110178, 0.9692621323237405
  uas = 0.451112554815657, las = 0.39296735423095663
  uas = 0.48609637998616556, las = 0.4384136499884713

numFeatures = 4096
  0.7797844043119138, 0.9836911916549734
  uas = 0.5085268799740134, las = 0.44461588435926586
  uas = 0.562646991007609, las = 0.5128890938436708  

numFeatures = 8192
  0.7845909748471698, 0.9915014164305949
  uas = 0.4428292999837583, las = 0.39207406204320283
  uas = 0.5104450080700945, las = 0.4653908231496426

numFeatures = 16384
  0.7889775537822576,  0.9962934526488576
  uas = 0.5111255481565697, las = 0.44624005197336364
  uas = 0.5887018676504496, las = 0.5427253862116671
