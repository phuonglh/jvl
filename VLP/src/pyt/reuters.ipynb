{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(root='../../dat/pyt', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = AG_NEWS(root='../../dat/pyt', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "  for _, text in data_iter:\n",
    "    yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = text_pipeline('here is an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "  ys, xs, offsets = [], [], [0]\n",
    "  for (y, x) in batch:\n",
    "    ys.append(label_pipeline(y))\n",
    "    ts = torch.tensor(text_pipeline(x), dtype=torch.int64)\n",
    "    xs.append(ts)\n",
    "    offsets.append(ts.size(0))\n",
    "  ys = torch.tensor(ys, dtype=torch.int64)\n",
    "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "  xs = torch.cat(xs)\n",
    "  return ys.to(device), xs.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(root='../../dat/pyt', split='train')\n",
    "training_data_loader = DataLoader(train_iter, batch_size=32, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_dim, num_class):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "    self.linear = nn.Linear(embed_dim, num_class)\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    self.embedding.weight.data.uniform_(-0.5, 0.5)\n",
    "    self.linear.weight.data.uniform_(-0.5, 0.5)\n",
    "    self.linear.bias.data.zero_()\n",
    "  \n",
    "  def forward(self, text, offsets):\n",
    "    embeded = self.embedding(text, offsets) # compute mean vectors of all words in the text\n",
    "    return self.linear(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(set([label for (label, _) in train_iter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = AG_NEWS(root='../../dat/pyt', split='train')\n",
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(vocab_size, 64, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (embedding): EmbeddingBag(95808, 64, mode=mean)\n",
       "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "  N = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  start_time = time.time()\n",
    "  for batch, (ys, xs, offsets) in enumerate(dataloader):\n",
    "    zs = model(xs, offsets)\n",
    "    loss = criterion(zs, ys)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch % 500 == 0:\n",
    "      elapsed = time.time() - start_time\n",
    "      loss, current = loss.item(), batch * len(xs)\n",
    "      print(f\"loss: {loss:>7f} [{current:>5d}/{N:>5d}], elapsed: {elapsed}\")\n",
    "      start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, criterion):\n",
    "  N = len(dataloader.dataset)\n",
    "  num_batch = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for (ys, xs, offsets) in dataloader:\n",
    "      zs = model(xs, offsets)\n",
    "      test_loss += criterion(zs, ys).item()\n",
    "      correct += (zs.argmax(1) == ys).type(torch.float).sum().item()\n",
    "  test_loss /= num_batch\n",
    "  correct /= N\n",
    "  print(f\"Test accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------\n",
      "loss: 1.277636 [    0/120000], elapsed: 0.005521297454833984\n",
      "loss: 1.213853 [641000/120000], elapsed: 2.127601146697998\n",
      "loss: 1.007157 [1315000/120000], elapsed: 2.0403480529785156\n",
      "loss: 1.140339 [2068500/120000], elapsed: 1.8243961334228516\n",
      "loss: 1.233848 [2690000/120000], elapsed: 1.8652877807617188\n",
      "loss: 1.075141 [3127500/120000], elapsed: 1.815431833267212\n",
      "loss: 1.141433 [4032000/120000], elapsed: 1.8189630508422852\n",
      "loss: 1.148036 [4788000/120000], elapsed: 1.8866550922393799\n",
      "Test accuracy: 60.2%, Avg loss: 1.097778 \n",
      "\n",
      "Epoch 2\n",
      "-------\n",
      "loss: 1.252485 [    0/120000], elapsed: 0.0038909912109375\n",
      "loss: 1.183322 [641000/120000], elapsed: 1.8534698486328125\n",
      "loss: 0.950009 [1315000/120000], elapsed: 1.7807862758636475\n",
      "loss: 1.092577 [2068500/120000], elapsed: 1.7615458965301514\n",
      "loss: 1.201568 [2690000/120000], elapsed: 1.7728180885314941\n",
      "loss: 1.030463 [3127500/120000], elapsed: 1.7955999374389648\n",
      "loss: 1.104581 [4032000/120000], elapsed: 1.8122670650482178\n",
      "loss: 1.111139 [4788000/120000], elapsed: 1.9192509651184082\n",
      "Test accuracy: 62.5%, Avg loss: 1.057005 \n",
      "\n",
      "Epoch 3\n",
      "-------\n",
      "loss: 1.223247 [    0/120000], elapsed: 0.003972053527832031\n",
      "loss: 1.151201 [641000/120000], elapsed: 1.8527679443359375\n",
      "loss: 0.891814 [1315000/120000], elapsed: 1.8793139457702637\n",
      "loss: 1.043363 [2068500/120000], elapsed: 1.8321373462677002\n",
      "loss: 1.166996 [2690000/120000], elapsed: 1.8427321910858154\n",
      "loss: 0.985691 [3127500/120000], elapsed: 1.8601689338684082\n",
      "loss: 1.067075 [4032000/120000], elapsed: 1.8117740154266357\n",
      "loss: 1.072649 [4788000/120000], elapsed: 1.7628509998321533\n",
      "Test accuracy: 64.5%, Avg loss: 1.016157 \n",
      "\n",
      "Epoch 4\n",
      "-------\n",
      "loss: 1.190682 [    0/120000], elapsed: 0.003869771957397461\n",
      "loss: 1.118534 [641000/120000], elapsed: 1.730010986328125\n",
      "loss: 0.833989 [1315000/120000], elapsed: 1.814856767654419\n",
      "loss: 0.994562 [2068500/120000], elapsed: 1.724632978439331\n",
      "loss: 1.130951 [2690000/120000], elapsed: 1.7293429374694824\n",
      "loss: 0.941523 [3127500/120000], elapsed: 1.7535479068756104\n",
      "loss: 1.029829 [4032000/120000], elapsed: 1.8520610332489014\n",
      "loss: 1.033456 [4788000/120000], elapsed: 1.8068468570709229\n",
      "Test accuracy: 66.2%, Avg loss: 0.975968 \n",
      "\n",
      "Epoch 5\n",
      "-------\n",
      "loss: 1.155838 [    0/120000], elapsed: 0.003968954086303711\n",
      "loss: 1.086387 [641000/120000], elapsed: 1.7587809562683105\n",
      "loss: 0.777847 [1315000/120000], elapsed: 1.7332890033721924\n",
      "loss: 0.947818 [2068500/120000], elapsed: 1.736711025238037\n",
      "loss: 1.094305 [2690000/120000], elapsed: 1.7384676933288574\n",
      "loss: 0.898586 [3127500/120000], elapsed: 1.7150468826293945\n",
      "loss: 0.993708 [4032000/120000], elapsed: 1.7169229984283447\n",
      "loss: 0.994468 [4788000/120000], elapsed: 1.7410290241241455\n",
      "Test accuracy: 67.9%, Avg loss: 0.937066 \n",
      "\n",
      "Epoch 6\n",
      "-------\n",
      "loss: 1.119860 [    0/120000], elapsed: 0.004243135452270508\n",
      "loss: 1.055657 [641000/120000], elapsed: 1.760739803314209\n",
      "loss: 0.724441 [1315000/120000], elapsed: 1.7610340118408203\n",
      "loss: 0.904321 [2068500/120000], elapsed: 1.7244131565093994\n",
      "loss: 1.057885 [2690000/120000], elapsed: 1.7599670886993408\n",
      "loss: 0.857377 [3127500/120000], elapsed: 1.7384591102600098\n",
      "loss: 0.959383 [4032000/120000], elapsed: 1.7270448207855225\n",
      "loss: 0.956465 [4788000/120000], elapsed: 1.7304110527038574\n",
      "Test accuracy: 69.6%, Avg loss: 0.899936 \n",
      "\n",
      "Epoch 7\n",
      "-------\n",
      "loss: 1.083819 [    0/120000], elapsed: 0.0041179656982421875\n",
      "loss: 1.026963 [641000/120000], elapsed: 1.7514028549194336\n",
      "loss: 0.674487 [1315000/120000], elapsed: 1.795051097869873\n",
      "loss: 0.864728 [2068500/120000], elapsed: 1.825664758682251\n",
      "loss: 1.022402 [2690000/120000], elapsed: 1.858382225036621\n",
      "loss: 0.818232 [3127500/120000], elapsed: 1.7659339904785156\n",
      "loss: 0.927263 [4032000/120000], elapsed: 1.8667500019073486\n",
      "loss: 0.920012 [4788000/120000], elapsed: 1.8682942390441895\n",
      "Test accuracy: 70.9%, Avg loss: 0.864898 \n",
      "\n",
      "Epoch 8\n",
      "-------\n",
      "loss: 1.048598 [    0/120000], elapsed: 0.004258155822753906\n",
      "loss: 1.000629 [641000/120000], elapsed: 1.9019262790679932\n",
      "loss: 0.628369 [1315000/120000], elapsed: 1.7224979400634766\n",
      "loss: 0.829229 [2068500/120000], elapsed: 1.7161920070648193\n",
      "loss: 0.988412 [2690000/120000], elapsed: 1.7202060222625732\n",
      "loss: 0.781330 [3127500/120000], elapsed: 1.7039439678192139\n",
      "loss: 0.897512 [4032000/120000], elapsed: 1.6985249519348145\n",
      "loss: 0.885428 [4788000/120000], elapsed: 1.7346529960632324\n",
      "Test accuracy: 72.2%, Avg loss: 0.832133 \n",
      "\n",
      "Epoch 9\n",
      "-------\n",
      "loss: 1.014849 [    0/120000], elapsed: 0.0040700435638427734\n",
      "loss: 0.976731 [641000/120000], elapsed: 1.8266921043395996\n",
      "loss: 0.586210 [1315000/120000], elapsed: 1.7964692115783691\n",
      "loss: 0.797691 [2068500/120000], elapsed: 1.7246100902557373\n",
      "loss: 0.956300 [2690000/120000], elapsed: 1.7276017665863037\n",
      "loss: 0.746719 [3127500/120000], elapsed: 1.7859251499176025\n",
      "loss: 0.870112 [4032000/120000], elapsed: 1.922480821609497\n",
      "loss: 0.852817 [4788000/120000], elapsed: 1.8178560733795166\n",
      "Test accuracy: 73.1%, Avg loss: 0.801704 \n",
      "\n",
      "Epoch 10\n",
      "-------\n",
      "loss: 0.982995 [    0/120000], elapsed: 0.003991127014160156\n",
      "loss: 0.955162 [641000/120000], elapsed: 1.8586227893829346\n",
      "loss: 0.547946 [1315000/120000], elapsed: 1.7467670440673828\n",
      "loss: 0.769803 [2068500/120000], elapsed: 1.831083059310913\n",
      "loss: 0.926291 [2690000/120000], elapsed: 2.2057087421417236\n",
      "loss: 0.714354 [3127500/120000], elapsed: 1.9348468780517578\n",
      "loss: 0.844938 [4032000/120000], elapsed: 2.0030410289764404\n",
      "loss: 0.822131 [4788000/120000], elapsed: 1.7430672645568848\n",
      "Test accuracy: 74.2%, Avg loss: 0.773585 \n",
      "\n",
      "Epoch 11\n",
      "-------\n",
      "loss: 0.953260 [    0/120000], elapsed: 0.004080057144165039\n",
      "loss: 0.935710 [641000/120000], elapsed: 1.7362868785858154\n",
      "loss: 0.513403 [1315000/120000], elapsed: 1.7401649951934814\n",
      "loss: 0.745180 [2068500/120000], elapsed: 1.723479986190796\n",
      "loss: 0.898475 [2690000/120000], elapsed: 1.9565320014953613\n",
      "loss: 0.684136 [3127500/120000], elapsed: 1.8702061176300049\n",
      "loss: 0.821810 [4032000/120000], elapsed: 1.8667020797729492\n",
      "loss: 0.793236 [4788000/120000], elapsed: 1.8945472240447998\n",
      "Test accuracy: 75.0%, Avg loss: 0.747689 \n",
      "\n",
      "Epoch 12\n",
      "-------\n",
      "loss: 0.925710 [    0/120000], elapsed: 0.004039287567138672\n",
      "loss: 0.918106 [641000/120000], elapsed: 1.9163672924041748\n",
      "loss: 0.482339 [1315000/120000], elapsed: 1.9968531131744385\n",
      "loss: 0.723436 [2068500/120000], elapsed: 1.940382957458496\n",
      "loss: 0.872837 [2690000/120000], elapsed: 1.9953360557556152\n",
      "loss: 0.655938 [3127500/120000], elapsed: 1.8349621295928955\n",
      "loss: 0.800538 [4032000/120000], elapsed: 1.9931731224060059\n",
      "loss: 0.765960 [4788000/120000], elapsed: 1.870002031326294\n",
      "Test accuracy: 75.8%, Avg loss: 0.723887 \n",
      "\n",
      "Epoch 13\n",
      "-------\n",
      "loss: 0.900299 [    0/120000], elapsed: 0.004083156585693359\n",
      "loss: 0.902073 [641000/120000], elapsed: 2.326306104660034\n",
      "loss: 0.454483 [1315000/120000], elapsed: 2.271743059158325\n",
      "loss: 0.704210 [2068500/120000], elapsed: 2.0253350734710693\n",
      "loss: 0.849295 [2690000/120000], elapsed: 2.0225179195404053\n",
      "loss: 0.629626 [3127500/120000], elapsed: 2.0739729404449463\n",
      "loss: 0.780934 [4032000/120000], elapsed: 1.782407283782959\n",
      "loss: 0.740134 [4788000/120000], elapsed: 2.004732131958008\n",
      "Test accuracy: 76.6%, Avg loss: 0.702029 \n",
      "\n",
      "Epoch 14\n",
      "-------\n",
      "loss: 0.876910 [    0/120000], elapsed: 0.0050809383392333984\n",
      "loss: 0.887345 [641000/120000], elapsed: 1.794842004776001\n",
      "loss: 0.429548 [1315000/120000], elapsed: 1.9319531917572021\n",
      "loss: 0.687185 [2068500/120000], elapsed: 1.801203966140747\n",
      "loss: 0.827719 [2690000/120000], elapsed: 1.8205821514129639\n",
      "loss: 0.605073 [3127500/120000], elapsed: 1.7875730991363525\n",
      "loss: 0.762821 [4032000/120000], elapsed: 1.7848081588745117\n",
      "loss: 0.715610 [4788000/120000], elapsed: 1.824040174484253\n",
      "Test accuracy: 77.1%, Avg loss: 0.681955 \n",
      "\n",
      "Epoch 15\n",
      "-------\n",
      "loss: 0.855386 [    0/120000], elapsed: 0.003943920135498047\n",
      "loss: 0.873690 [641000/120000], elapsed: 1.987617015838623\n",
      "loss: 0.407246 [1315000/120000], elapsed: 1.9601900577545166\n",
      "loss: 0.672083 [2068500/120000], elapsed: 2.002574920654297\n",
      "loss: 0.807960 [2690000/120000], elapsed: 2.172769069671631\n",
      "loss: 0.582160 [3127500/120000], elapsed: 2.103429079055786\n",
      "loss: 0.746040 [4032000/120000], elapsed: 1.9228241443634033\n",
      "loss: 0.692267 [4788000/120000], elapsed: 2.197639226913452\n",
      "Test accuracy: 77.9%, Avg loss: 0.663507 \n",
      "\n",
      "Epoch 16\n",
      "-------\n",
      "loss: 0.835559 [    0/120000], elapsed: 0.007025003433227539\n",
      "loss: 0.860909 [641000/120000], elapsed: 2.1103322505950928\n",
      "loss: 0.387302 [1315000/120000], elapsed: 1.9798693656921387\n",
      "loss: 0.658665 [2068500/120000], elapsed: 1.8554818630218506\n",
      "loss: 0.789863 [2690000/120000], elapsed: 1.829941987991333\n",
      "loss: 0.560776 [3127500/120000], elapsed: 1.8447530269622803\n",
      "loss: 0.730446 [4032000/120000], elapsed: 1.8720629215240479\n",
      "loss: 0.670007 [4788000/120000], elapsed: 1.8864140510559082\n",
      "Test accuracy: 78.4%, Avg loss: 0.646535 \n",
      "\n",
      "Epoch 17\n",
      "-------\n",
      "loss: 0.817261 [    0/120000], elapsed: 0.004705905914306641\n",
      "loss: 0.848841 [641000/120000], elapsed: 3.0115561485290527\n",
      "loss: 0.369451 [1315000/120000], elapsed: 2.0076417922973633\n",
      "loss: 0.646721 [2068500/120000], elapsed: 2.0214998722076416\n",
      "loss: 0.773274 [2690000/120000], elapsed: 1.9315950870513916\n",
      "loss: 0.540821 [3127500/120000], elapsed: 2.0424551963806152\n",
      "loss: 0.715910 [4032000/120000], elapsed: 1.8479065895080566\n",
      "loss: 0.648759 [4788000/120000], elapsed: 1.8299078941345215\n",
      "Test accuracy: 78.8%, Avg loss: 0.630897 \n",
      "\n",
      "Epoch 18\n",
      "-------\n",
      "loss: 0.800338 [    0/120000], elapsed: 0.00402379035949707\n",
      "loss: 0.837355 [641000/120000], elapsed: 1.9903619289398193\n",
      "loss: 0.353450 [1315000/120000], elapsed: 2.0293691158294678\n",
      "loss: 0.636066 [2068500/120000], elapsed: 1.9712300300598145\n",
      "loss: 0.758048 [2690000/120000], elapsed: 1.744840145111084\n",
      "loss: 0.522202 [3127500/120000], elapsed: 1.7735137939453125\n",
      "loss: 0.702317 [4032000/120000], elapsed: 1.7760441303253174\n",
      "loss: 0.628462 [4788000/120000], elapsed: 2.144439935684204\n",
      "Test accuracy: 79.4%, Avg loss: 0.616465 \n",
      "\n",
      "Epoch 19\n",
      "-------\n",
      "loss: 0.784650 [    0/120000], elapsed: 0.004330873489379883\n",
      "loss: 0.826352 [641000/120000], elapsed: 2.1234090328216553\n",
      "loss: 0.339078 [1315000/120000], elapsed: 2.4851741790771484\n",
      "loss: 0.626539 [2068500/120000], elapsed: 2.0107920169830322\n",
      "loss: 0.744049 [2690000/120000], elapsed: 1.8298370838165283\n",
      "loss: 0.504830 [3127500/120000], elapsed: 2.2214772701263428\n",
      "loss: 0.689562 [4032000/120000], elapsed: 1.8659629821777344\n",
      "loss: 0.609071 [4788000/120000], elapsed: 2.0558462142944336\n",
      "Test accuracy: 79.9%, Avg loss: 0.603121 \n",
      "\n",
      "Epoch 20\n",
      "-------\n",
      "loss: 0.770075 [    0/120000], elapsed: 0.004272937774658203\n",
      "loss: 0.815754 [641000/120000], elapsed: 2.215933322906494\n",
      "loss: 0.326136 [1315000/120000], elapsed: 1.8815031051635742\n",
      "loss: 0.617998 [2068500/120000], elapsed: 1.8799970149993896\n",
      "loss: 0.731154 [2690000/120000], elapsed: 1.8112061023712158\n",
      "loss: 0.488622 [3127500/120000], elapsed: 1.741250991821289\n",
      "loss: 0.677553 [4032000/120000], elapsed: 1.729372262954712\n",
      "loss: 0.590546 [4788000/120000], elapsed: 1.7311220169067383\n",
      "Test accuracy: 80.2%, Avg loss: 0.590760 \n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "  train_iter = AG_NEWS(root='../../dat/pyt', split='train')\n",
    "  test_iter = AG_NEWS(root='../../dat/pyt', split='test')\n",
    "  training_data_loader = DataLoader(train_iter, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "  test_data_loader = DataLoader(test_iter, batch_size=32, shuffle=False, collate_fn=collate_batch)  \n",
    "  print(f\"Epoch {t+1}\\n-------\")\n",
    "  train(training_data_loader, model, criterion, optimizer)\n",
    "  test(test_data_loader, model, criterion)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
